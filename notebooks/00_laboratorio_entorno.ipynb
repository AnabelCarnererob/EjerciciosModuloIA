{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e53e3043",
   "metadata": {},
   "source": [
    "# Laboratorio 0 — Preparación del entorno y buenas prácticas\n",
    "\n",
    "Este cuaderno define convenciones (reproducibilidad, estructura de experimentos y métricas) que se reutilizarán en el resto de prácticas.\n",
    "\n",
    "## Objetivos\n",
    "- Verificar el entorno (versiones, GPU si aplica).\n",
    "- Establecer semillas y una estructura mínima de experimento.\n",
    "- Adoptar un flujo de trabajo repetible: datos → modelo → evaluación → registro.\n",
    "\n",
    "## Requisitos\n",
    "- Python 3.10+ recomendado\n",
    "- Jupyter\n",
    "- numpy, pandas, matplotlib, scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a4a10",
   "metadata": {},
   "source": [
    "## 1) Comprobación del entorno\n",
    "\n",
    "Ejecuta la siguiente celda para ver versiones. Si alguna librería falta, instala con `pip install ...` (idealmente dentro de un entorno virtual).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5917ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.14.0\n",
      "Plataforma: Windows-11-10.0.26100-SP0\n",
      "NumPy: 2.3.4\n",
      "Pandas: 2.3.3\n",
      "Scikit-learn: 1.8.0\n",
      "Matplotlib: 3.10.7\n"
     ]
    }
   ],
   "source": [
    "import sys, platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Plataforma:\", platform.platform())\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "print(\"Scikit-learn:\", sklearn.__version__)\n",
    "print(\"Matplotlib:\", matplotlib.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c057c5f4",
   "metadata": {},
   "source": [
    "## 2) Reproducibilidad\n",
    "\n",
    "En ciencia de datos es habitual obtener resultados distintos entre ejecuciones por aleatoriedad (barajado de datos, inicialización de pesos, etc.). \n",
    "Aquí fijamos semillas y definimos utilidades para evaluar de forma consistente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a6f542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semilla fijada: 42\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"Semilla fijada:\", SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39686e95",
   "metadata": {},
   "source": [
    "## 3) Utilidades de evaluación\n",
    "\n",
    "Definimos dos funciones prácticas: una para dividir conjuntos y otra para reportar métricas de forma estándar.\n",
    "Más adelante se extenderán para CV y NLP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score, accuracy_score, f1_score\n",
    "\n",
    "\"\"\"\n",
    "Dividir los datos en Datos de entrenamiento y Datos test\n",
    "Usa siempre la misma semilla (para tener siempre los mismos resultados)\n",
    "\"\"\"\n",
    "def split(X, y, test_size=0.2, seed=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "\"\"\"\n",
    "Función que recibe valores reales (y_true) y valores predichos (y_pred)\n",
    "\"\"\"\n",
    "def regression_report(y_true, y_pred) -> Dict[str, float]:\n",
    "    # Lo devuelve como float para poder guardarlo en JSON.\n",
    "    return {\n",
    "        # MAE: error promedio\n",
    "        \"MAE\": float(mean_absolute_error(y_true, y_pred)),\n",
    "\n",
    "        # Diferencia promedio entre los valores que predice tu modelo y los valores reales\n",
    "        # RMSE: error penalizando errores grandes\n",
    "        \"RMSE\": float(root_mean_squared_error(y_true, y_pred, squared=False)),\n",
    "        \n",
    "        # Proporción de la variabilidad de la variable dependiente es explicada por el modelo\n",
    "        # R²: qué tan bien explica el modelo los datos\n",
    "        \"R2\": float(r2_score(y_true, y_pred)),\n",
    "    }\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Función para modelos de clasificación.\n",
    "\n",
    "Accuracy: porcentaje de aciertos\n",
    "F1 macro: balance entre precisión y recall\n",
    "\"\"\"\n",
    "def classification_report_simple(y_true, y_pred) -> Dict[str, float]:\n",
    "    return {\n",
    "        \"Accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"F1 (macro)\": float(f1_score(y_true, y_pred, average=\"macro\")),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f271d2b",
   "metadata": {},
   "source": [
    "## 4) Registro mínimo de experimentos\n",
    "\n",
    "No hace falta una plataforma compleja para empezar; basta con guardar:\n",
    "- configuración (modelo/hiperparámetros),\n",
    "- métricas,\n",
    "- fecha/hora y semilla.\n",
    "\n",
    "Esto permite comparar versiones sin perderse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7eb52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listo. Usa log_experiment(...) en los laboratorios.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\"\"\"\n",
    "name: nombre del experimento\n",
    "config: cómo entrenaste el modelo\n",
    "metrics: resultados\n",
    "X: dataset (opcional)\n",
    "out_dir: carpeta donde guardar\n",
    "\"\"\"\n",
    "def log_experiment(name: str, config: Dict[str, Any], metrics: Dict[str, Any], out_dir=\"experimentos\"):\n",
    "    # Crea la carpeta si no existe.\n",
    "    Path(out_dir).mkdir(exist_ok=True)\n",
    "\n",
    "    # Toda la información del experimento junta.\n",
    "    payload = {\n",
    "        \"name\": name,\n",
    "        \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"seed\": SEED,\n",
    "        \"config\": config,\n",
    "        \"metrics\": metrics,\n",
    "    }\n",
    "\n",
    "    # Crear una archivo json con todos los datos, fecha y hora - Guarda el archivo en .json\n",
    "    path = Path(out_dir) / f\"{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    path.write_text(json.dumps(payload, ensure_ascii=False, indent=2))\n",
    "    return str(path)\n",
    "\n",
    "print(\"Listo. Usa log_experiment(...) en los laboratorios.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf37a813",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "### Ejercicio 1: Entorno reproducible\n",
    "Crea un entorno virtual (venv/conda) e instala las librerías necesarias. Exporta un `requirements.txt` mínimo para estos laboratorios.\n",
    "\n",
    "**Entregables**\n",
    "- Comando(s) usados\n",
    "- Archivo `requirements.txt`\n",
    "\n",
    "**Criterios de evaluación**\n",
    "- El entorno se crea y activa correctamente\n",
    "- El requirements incluye versiones o, como mínimo, librerías clave\n",
    "- Se documenta cómo reproducirlo\n",
    "\n",
    "\n",
    "-------------------------------------------------------------\n",
    "### Comandos para desplegar entorno\n",
    "**Reproducir entorno virtual en Windows 11**\n",
    "\n",
    "1. PowerShell -> Crear entorno -- Dentro de la carpeta de nuestro codigo - crea una carpeta env\n",
    "\n",
    "    python -m venv env\n",
    "\n",
    "2. Ejecutar en PowerShell:\n",
    "\n",
    "    Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process\n",
    "\n",
    "3. Activar entorno\n",
    "    \n",
    "    .\\env\\Scripts\\Activate.ps1\n",
    "\n",
    "4. Instalar librerías\n",
    "\n",
    "    pip install pandas matplotlib scikit-learn joblib\n",
    "\n",
    "5. Exportar requirements\n",
    "    \n",
    "    pip freeze > requirements.txt\n",
    "\n",
    "3. Desactivar entorno\n",
    "    \n",
    "    deactivate\n",
    "-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147dda4f",
   "metadata": {},
   "source": [
    "\n",
    "### Ejercicio 2: Plantilla de experimento\n",
    "Extiende `log_experiment` para que también guarde el tamaño del dataset y el nombre de las columnas/variables.\n",
    "\n",
    "**Entregables**\n",
    "- Función modificada\n",
    "- Ejemplo de uso con un dataset pequeño\n",
    "\n",
    "**Pistas**\n",
    "- `X.shape` y `list(X.columns)` si trabajas con pandas\n",
    "\n",
    "**Criterios de evaluación**\n",
    "- Registra información adicional útil\n",
    "- No rompe compatibilidad con el uso anterior\n",
    "- El JSON queda legible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906f38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experimentos\\\\regresion_demo_20260122_171051.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Definir en la funcion que queremos modificar un nuevo parámetro (X) darle el valor de NONE por si no tiene valor.\n",
    "Agregar en el nuevo parámetro al playload (El conjunto de datos que queremos guardar, enviar o registrar como una sola unidad)\n",
    "\"\"\"\n",
    "def log_experiment(name: str, config: Dict[str, Any], metrics: Dict[str, Any], X: pd.DataFrame | None = None, out_dir=\"experimentos\"):\n",
    "    dataset_info = None\n",
    "\n",
    "    if X is not None:\n",
    "        dataset_info = {\n",
    "            \"n_rows\": X.shape[0],\n",
    "            \"n_columns\": X.shape[1],\n",
    "            \"columns\": list(X.columns)\n",
    "        }\n",
    "    \n",
    "    Path(out_dir).mkdir(exist_ok=True)\n",
    "    payload = {\n",
    "        \"name\": name,\n",
    "        \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"seed\": SEED,\n",
    "        \"config\": config,\n",
    "        \"metrics\": metrics,\n",
    "        \"dataset\": dataset_info\n",
    "    }\n",
    "    path = Path(out_dir) / f\"{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    path.write_text(json.dumps(payload, ensure_ascii=False, indent=2))\n",
    "    return str(path)\n",
    "\n",
    "\n",
    "# Dataset de ejemplo\n",
    "df = pd.DataFrame({\n",
    "    \"edad\": [25, 32, 40, 28],\n",
    "    \"ingresos\": [30000, 45000, 60000, 38000]\n",
    "})\n",
    "\n",
    "# Simulamos métricas\n",
    "metrics = {\n",
    "    \"MAE\": 1234.5,\n",
    "    \"RMSE\": 1500.2,\n",
    "    \"R2\": 0.82\n",
    "}\n",
    "\n",
    "# Configuración ficticia\n",
    "config = {\n",
    "    \"model\": \"LinearRegression\",\n",
    "    \"test_size\": 0.2\n",
    "}\n",
    "\n",
    "log_experiment(\n",
    "    name=\"regresion_demo\",\n",
    "    config=config,\n",
    "    metrics=metrics,\n",
    "    X=df\n",
    ")\n",
    "\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
